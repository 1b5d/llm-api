version: '3'

services:
  app:
    image: 1b5d/llm-api:0.0.4-gptq-llama-triton
    container_name: llm-api-app
    ports:
      - "8000:8000"
    environment:
      - LLM_API_MODELS_DIR=/models
    volumes:
      - "./models:/models:rw"
      - "./config.yaml:/llm-api/config.yaml:ro"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]
